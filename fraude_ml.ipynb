{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911eb367",
   "metadata": {},
   "source": [
    "# üí≥ Detec√ß√£o de Fraudes em Transa√ß√µes Financeiras com Machine Learning\n",
    "### Disciplina: Engenharia de Machine Learning\n",
    "\n",
    "**Equipe:**  \n",
    "- Anderson de Matos Guimar√£es  \n",
    "- Gustavo Stefano Thomazinho  \n",
    "- Leonardo Rodrigues Vianna de Medeiros Lopes  \n",
    "- Renan Ost  \n",
    "\n",
    "**Professor:** Marcelo Carboni Gomes  \n",
    "**Metodologia:** CRISP-DM  \n",
    "**Dataset:** [Credit Card Fraud Detection (Kaggle)](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22733e",
   "metadata": {},
   "source": [
    "## 1. Entendimento do Neg√≥cio\n",
    "\n",
    "Este projeto tem como objetivo desenvolver um modelo preditivo capaz de detectar transa√ß√µes fraudulentas com cart√£o de cr√©dito, utilizando algoritmos de aprendizado de m√°quina supervisionado.\n",
    "\n",
    "Fraudes financeiras representam um desafio para institui√ß√µes banc√°rias, pois causam preju√≠zos significativos e minam a confian√ßa dos clientes. O foco deste projeto √© **maximizar a detec√ß√£o de transa√ß√µes fraudulentas** (alta taxa de recall) sem comprometer excessivamente a taxa de falsos positivos.\n",
    "\n",
    "A base de dados utilizada √© real, anonimizadas por PCA, e extremamente desbalanceada ‚Äî apenas **0,172% das transa√ß√µes s√£o fraudes**. Isso imp√µe desafios na modelagem e na avalia√ß√£o de desempenho dos modelos.\n",
    "\n",
    "A metodologia adotada ser√° o **CRISP-DM**, seguindo as etapas: entendimento do neg√≥cio, entendimento dos dados, prepara√ß√£o, modelagem, avalia√ß√£o e apresenta√ß√£o.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4df25",
   "metadata": {},
   "source": [
    "### 1.1 Documenta√ß√£o T√©cnica do Dataset\n",
    "\n",
    "Esta se√ß√£o apresenta a documenta√ß√£o t√©cnica detalhada do dataset utilizado no projeto, conforme exigido pelo professor:\n",
    "\n",
    "#### 1) R√≥tulos (nomes das vari√°veis)\n",
    "\n",
    "- `Time`: tempo (em segundos) desde a primeira transa√ß√£o registrada.\n",
    "- `Amount`: valor da transa√ß√£o em euros (‚Ç¨).\n",
    "- `V1` a `V28`: componentes principais resultantes de uma transforma√ß√£o PCA aplicada para anonimiza√ß√£o dos dados originais. Seus significados exatos n√£o s√£o p√∫blicos, mas mant√™m relev√¢ncia estat√≠stica.\n",
    "- `Class`: vari√°vel-alvo. Valores:\n",
    "  - `0` ‚Üí transa√ß√£o leg√≠tima\n",
    "  - `1` ‚Üí transa√ß√£o fraudulenta\n",
    "\n",
    "#### 2) Tipos de dados\n",
    "\n",
    "| Coluna        | Tipo de dado |\n",
    "|---------------|--------------|\n",
    "| `Time`        | `float64`    |\n",
    "| `Amount`      | `float64`    |\n",
    "| `V1` a `V28`  | `float64`    |\n",
    "| `Class`       | `int64`      |\n",
    "\n",
    "> Obs.: O dataset n√£o cont√©m valores ausentes (NaN) nem temporais no formato `datetime` (NaT).\n",
    "\n",
    "#### 3) Quantitativos\n",
    "\n",
    "- **Total de registros (linhas):** 284.807\n",
    "- **Total de vari√°veis (colunas):** 31\n",
    "- **Total de transa√ß√µes fraudulentas (`Class = 1`):** 492  \n",
    "- **Propor√ß√£o de fraudes:** aproximadamente 0,172%\n",
    "- **Transa√ß√µes leg√≠timas (`Class = 0`):** 284.315\n",
    "\n",
    "#### 4) N√∫mero de datasets\n",
    "\n",
    "- Apenas **um dataset** est√° sendo utilizado neste projeto:\n",
    "  - `creditcard.csv`\n",
    "\n",
    "#### 5) Relacionamentos\n",
    "\n",
    "- O dataset √© **auto contido** (flat table).\n",
    "- N√£o h√° relacionamento com outras tabelas ou bases externas.\n",
    "- Cada linha representa uma transa√ß√£o financeira independente.\n",
    "\n",
    "#### 6) Formato dos dados\n",
    "\n",
    "- **Formato:** `CSV` (Comma-Separated Values)\n",
    "- **Codifica√ß√£o:** UTF-8\n",
    "- **Fonte oficial:** Kaggle  \n",
    "  [Credit Card Fraud Detection ‚Äì Kaggle: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)\n",
    "\n",
    "> Este dataset foi coletado em uma parceria entre o grupo Worldline e o Machine Learning Group da Universit√© Libre de Bruxelles (ULB), e contempla transa√ß√µes realizadas por portadores de cart√µes europeus em setembro de 2013.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1457bba",
   "metadata": {},
   "source": [
    "## üîß Prepara√ß√£o Inicial\n",
    "\n",
    "Nesta c√©lula, importamos as bibliotecas necess√°rias para a an√°lise e carregamos o dataset diretamente a partir de uma URL p√∫blica. O dataset √© armazenado em um DataFrame do pandas (`df`) para posterior an√°lise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c39149",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Bibliotecas principais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configura√ß√µes gr√°ficas\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Carregando o dataset via URL\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# C√≥pia de seguran√ßa do dataset original (para compara√ß√µes futuras)\n",
    "df_original = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6478e9",
   "metadata": {},
   "source": [
    "## 2. Entendimento dos Dados\n",
    "\n",
    "Nesta etapa, realizamos uma explora√ß√£o inicial da estrutura do dataset para obter uma vis√£o geral da sua composi√ß√£o e qualidade.\n",
    "\n",
    "O objetivo principal √© compreender:\n",
    "\n",
    "- O tamanho da base de dados\n",
    "- A presen√ßa de valores ausentes (NaN ou NaT)\n",
    "- Os tipos de dados de cada vari√°vel\n",
    "- As primeiras e √∫ltimas linhas da base\n",
    "- Estat√≠sticas descritivas b√°sicas\n",
    "\n",
    "Essas an√°lises s√£o essenciais para orientar as decis√µes nas etapas seguintes de prepara√ß√£o e modelagem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e422b",
   "metadata": {},
   "source": [
    "### üîé Verificando o tamanho do dataset\n",
    "\n",
    "O m√©todo `df.shape` retorna uma tupla com o n√∫mero de linhas e colunas do DataFrame. Essa √© uma informa√ß√£o fundamental para entendermos a dimens√£o da base de dados que ser√° analisada e modelada.\n",
    "\n",
    "- O primeiro valor representa o n√∫mero de registros (transa√ß√µes).\n",
    "- O segundo valor representa o n√∫mero de vari√°veis (colunas).\n",
    "\n",
    "Essa an√°lise nos d√° uma ideia inicial da escala do problema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0be49d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Verificando o n√∫mero de linhas e colunas\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0c950",
   "metadata": {},
   "source": [
    "### üßæ Visualizando as primeiras linhas do dataset\n",
    "\n",
    "O m√©todo `df.head()` exibe, por padr√£o, as **cinco primeiras linhas** do DataFrame. Isso permite observar:\n",
    "\n",
    "- A estrutura dos dados\n",
    "- A ordem das colunas\n",
    "- Exemplos reais de valores presentes\n",
    "- Poss√≠veis inconsist√™ncias ou padr√µes\n",
    "\n",
    "√â uma das primeiras formas de \"enxergar\" o conte√∫do da base.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a5f4f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizando as primeiras 5 linhas do dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df512d",
   "metadata": {},
   "source": [
    "### üìÑ Visualizando as √∫ltimas linhas do dataset\n",
    "\n",
    "O m√©todo `df.tail()` retorna, por padr√£o, as **cinco √∫ltimas linhas** do DataFrame.  \n",
    "Isso √© √∫til para verificar se h√° algum comportamento at√≠pico no final da base de dados, como:\n",
    "\n",
    "- Registros incompletos\n",
    "- Campos zerados ou nulos\n",
    "- Mudan√ßas de padr√£o\n",
    "\n",
    "Tamb√©m complementa a visualiza√ß√£o iniciada com `df.head()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bf1bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizando as 5 √∫ltimas linhas do dataset\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784ead4",
   "metadata": {},
   "source": [
    "### üß± Verificando estrutura e tipos de dados com `.info()`\n",
    "\n",
    "O m√©todo `df.info()` fornece um resumo das colunas do DataFrame, incluindo:\n",
    "\n",
    "- N√∫mero total de entradas (linhas)\n",
    "- Nome de cada coluna\n",
    "- Quantidade de valores n√£o nulos\n",
    "- Tipo de dado de cada coluna\n",
    "\n",
    "√â fundamental para:\n",
    "\n",
    "- Identificar valores ausentes (NaN ou NaT)\n",
    "- Verificar a consist√™ncia dos tipos de dados (ex: `float64`, `int64`)\n",
    "- Estimar o uso de mem√≥ria do dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2ea51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Resumo da estrutura do DataFrame\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79668b80",
   "metadata": {},
   "source": [
    "### üìä Estat√≠sticas descritivas com `.describe()`\n",
    "\n",
    "O m√©todo `df.describe()` gera estat√≠sticas descritivas para as colunas num√©ricas do DataFrame, como:\n",
    "\n",
    "- M√©dia\n",
    "- Desvio padr√£o\n",
    "- Valores m√≠nimos e m√°ximos\n",
    "- Quartis (Q1, Q2 - mediana, Q3)\n",
    "\n",
    "Esses dados ajudam a identificar:\n",
    "\n",
    "- Distribui√ß√µes assim√©tricas\n",
    "- Outliers (valores extremos)\n",
    "- Escalas distintas entre vari√°veis\n",
    "\n",
    "√â especialmente √∫til antes de aplicar transforma√ß√µes como normaliza√ß√£o ou padroniza√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dfd01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas das vari√°veis num√©ricas\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4b4ac2",
   "metadata": {},
   "source": [
    "## 3. Pr√©-processamento de Texto (An√°lise Auxiliar)\n",
    "\n",
    "Como solicitado pelo professor, inclu√≠mos nesta etapa a aplica√ß√£o de t√©cnicas de pr√©-processamento textual.  \n",
    "Embora o dataset principal (`creditcard.csv`) n√£o contenha campos de texto, constru√≠mos um **texto explicativo do projeto** como corpus base.\n",
    "\n",
    "As etapas aplicadas foram:\n",
    "\n",
    "- Minifica√ß√£o do texto (lowercase)\n",
    "- Remo√ß√£o de pontua√ß√£o, acentua√ß√£o e d√≠gitos\n",
    "- Remo√ß√£o de stopwords\n",
    "- Stemming com `PorterStemmer`\n",
    "- Vetoriza√ß√£o com TF-IDF\n",
    "\n",
    "A seguir, mostramos cada etapa aplicada ao texto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db480646",
   "metadata": {},
   "source": [
    "### üìö Importa√ß√£o das bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144c195",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9742b4c",
   "metadata": {},
   "source": [
    "### üßæ Texto explicativo do projeto (usado como corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee76a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "texto_projeto = \"\"\"Este projeto tem como objetivo desenvolver um sistema inteligente capaz de detectar fraudes em transa√ß√µes financeiras \n",
    "por meio de t√©cnicas avan√ßadas de aprendizado de m√°quina supervisionado. A solu√ß√£o proposta busca identificar padr√µes \n",
    "an√¥malos em grandes volumes de dados, utilizando etapas rigorosas de pr√©-processamento textual, vetoriza√ß√£o e \n",
    "modelagem preditiva. O desempenho dos modelos ser√° avaliado com base em m√©tricas como acur√°cia, precis√£o, recall e \n",
    "F1-score, assegurando sua robustez e aplicabilidade em contextos reais. Destinado a institui√ß√µes financeiras, o \n",
    "sistema funcionar√° como uma ferramenta preventiva, refor√ßando a seguran√ßa digital e contribuindo para a mitiga√ß√£o de \n",
    "perdas decorrentes de atividades fraudulentas.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476cdd8",
   "metadata": {},
   "source": [
    "### üßº Pr√©-processamento inicial (min√∫sculas, pontua√ß√£o, acentos, d√≠gitos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb8929",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Min√∫sculas\n",
    "texto = texto_projeto.lower()\n",
    "\n",
    "# 2. Remo√ß√£o de pontua√ß√£o\n",
    "punctuation = string.punctuation\n",
    "trantab = str.maketrans(punctuation, len(punctuation) * ' ')\n",
    "texto = texto.translate(trantab)\n",
    "\n",
    "# 3. Remo√ß√£o de acentos\n",
    "texto = unidecode(texto)\n",
    "\n",
    "# 4. Remo√ß√£o de d√≠gitos\n",
    "texto = re.sub(r'\\d+', '', texto)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35f462",
   "metadata": {},
   "source": [
    "### ‚ùå Remo√ß√£o de stopwords (com `try-except`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89df9f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    stopwords_list = stopwords.words('portuguese')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    stopwords_list = stopwords.words('portuguese')\n",
    "\n",
    "palavras = texto.split()\n",
    "palavras_filtradas = [palavra for palavra in palavras if palavra not in stopwords_list and len(palavra) > 1]\n",
    "texto_limpo = \" \".join(palavras_filtradas)\n",
    "\n",
    "print(texto_limpo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b263b98",
   "metadata": {},
   "source": [
    "### üß™ Stemming com `PorterStemmer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcf19c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "texto_stemmed = \" \".join([stemmer.stem(palavra) for palavra in texto_limpo.split()])\n",
    "\n",
    "print(texto_stemmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d310fead",
   "metadata": {},
   "source": [
    "### üß† Vetoriza√ß√£o com TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e65189",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "corpus = np.array([\n",
    "    texto_stemmed,\n",
    "    \"sistema inteligente detectar padrao comportamento transacao financeira\"\n",
    "])\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_result = vectorizer.fit_transform(corpus)\n",
    "\n",
    "df_tfidf = pd.DataFrame.sparse.from_spmatrix(tfidf_result, columns=vectorizer.get_feature_names_out())\n",
    "df_tfidf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49941977",
   "metadata": {},
   "source": [
    "## 4. An√°lise Explorat√≥ria de Dados (EDA)\n",
    "\n",
    "Nesta etapa, buscamos explorar visualmente os dados para compreender a distribui√ß√£o de valores, detectar padr√µes, identificar valores discrepantes (outliers) e verificar o comportamento da vari√°vel-alvo `Class`.\n",
    "\n",
    "Al√©m disso, ser√£o aplicadas transforma√ß√µes simples para comparar o \"antes e depois\" dos dados, conforme exigido na atividade da disciplina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888fe485",
   "metadata": {},
   "source": [
    "### üéØ Distribui√ß√£o da vari√°vel-alvo `Class`\n",
    "\n",
    "Vamos visualizar a propor√ß√£o entre transa√ß√µes leg√≠timas (`Class = 0`) e fraudulentas (`Class = 1`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3e9bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='Class', data=df, palette='Set2')\n",
    "plt.title('Distribui√ß√£o das Transa√ß√µes (0 = Leg√≠tima, 1 = Fraude)')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Contagem')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2977e3a",
   "metadata": {},
   "source": [
    "A maior parte das transa√ß√µes √© leg√≠tima (`Class = 0`). Apenas **0,172%** dos registros representam fraudes (`Class = 1`), o que confirma que o dataset √© altamente desbalanceado.  \n",
    "Isso influenciar√° diretamente na escolha dos algoritmos e nas m√©tricas de avalia√ß√£o utilizadas posteriormente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295a1233",
   "metadata": {},
   "source": [
    "### üí∂ An√°lise da vari√°vel `Amount`\n",
    "\n",
    "Vamos analisar a distribui√ß√£o dos valores das transa√ß√µes antes de qualquer transforma√ß√£o, utilizando:\n",
    "\n",
    "- Histograma (para ver concentra√ß√£o)\n",
    "- Boxplot (para observar outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24139771",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(df['Amount'], bins=50, kde=True)\n",
    "plt.title('Distribui√ß√£o dos Valores das Transa√ß√µes (Antes da Normaliza√ß√£o)')\n",
    "plt.xlabel('Valor (‚Ç¨)')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200451ab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "sns.boxplot(x=df['Amount'])\n",
    "plt.title('Boxplot do Valor das Transa√ß√µes (Antes da Normaliza√ß√£o)')\n",
    "plt.xlabel('Valor (‚Ç¨)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf75af",
   "metadata": {},
   "source": [
    "Os gr√°ficos mostram que a maioria das transa√ß√µes possui valores baixos, concentrados abaixo de ‚Ç¨100.  \n",
    "Entretanto, existem outliers (valores muito altos), o que pode distorcer an√°lises e impactar algoritmos sens√≠veis √† escala, como regress√£o log√≠stica e KNN.\n",
    "\n",
    "Por isso, ser√° necess√°rio aplicar uma transforma√ß√£o de escala nos valores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87a817",
   "metadata": {},
   "source": [
    "### üîß Normaliza√ß√£o do valor da transa√ß√£o (`Amount`)\n",
    "\n",
    "Alguns algoritmos de Machine Learning s√£o sens√≠veis √† escala dos dados. Como a vari√°vel `Amount` apresenta uma grande varia√ß√£o e outliers, vamos aplicar a **normaliza√ß√£o com `StandardScaler`**, que transforma os dados para que tenham m√©dia 0 e desvio padr√£o 1.\n",
    "\n",
    "Dessa forma, o algoritmo ser√° menos influenciado por diferen√ßas de escala.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d9b77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instanciando o normalizador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Aplicando ao Amount\n",
    "df['Amount_Scaled'] = scaler.fit_transform(df[['Amount']])\n",
    "\n",
    "# Verificando estat√≠sticas antes e depois\n",
    "df[['Amount', 'Amount_Scaled']].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47128a5",
   "metadata": {},
   "source": [
    "### üìä Compara√ß√£o ‚ÄúAntes e Depois‚Äù com Gr√°ficos\n",
    "\n",
    "Vamos comparar a distribui√ß√£o da vari√°vel `Amount` antes e depois da transforma√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213c808",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14, 4))\n",
    "\n",
    "# Boxplot original\n",
    "sns.boxplot(x=df['Amount'], ax=axs[0], color='skyblue')\n",
    "axs[0].set_title('Antes da Normaliza√ß√£o')\n",
    "axs[0].set_xlabel('Amount (‚Ç¨)')\n",
    "\n",
    "# Boxplot escalado\n",
    "sns.boxplot(x=df['Amount_Scaled'], ax=axs[1], color='lightgreen')\n",
    "axs[1].set_title('Depois da Normaliza√ß√£o')\n",
    "axs[1].set_xlabel('Amount Scaled')\n",
    "\n",
    "plt.suptitle('Boxplots Comparativos - Amount Original vs Normalizado')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d5024",
   "metadata": {},
   "source": [
    "### üìä Histograma do valor normalizado das transa√ß√µes\n",
    "\n",
    "Para complementar a visualiza√ß√£o, vamos analisar o histograma da vari√°vel `Amount_Scaled` ap√≥s a transforma√ß√£o com `StandardScaler`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7331c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(df['Amount_Scaled'], bins=50, kde=True, color='green')\n",
    "plt.title('Distribui√ß√£o do Valor das Transa√ß√µes Ap√≥s Normaliza√ß√£o')\n",
    "plt.xlabel('Amount Scaled')\n",
    "plt.ylabel('Frequ√™ncia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed925f",
   "metadata": {},
   "source": [
    "A transforma√ß√£o com `StandardScaler` centralizou os dados de `Amount_Scaled` em torno de zero e reduziu a vari√¢ncia.  \n",
    "Isso facilita a aprendizagem dos algoritmos e mitiga a influ√™ncia de outliers extremos.  \n",
    "O valor original foi mantido em `Amount` para fins de refer√™ncia, enquanto o modelo utilizar√° `Amount_Scaled`.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
